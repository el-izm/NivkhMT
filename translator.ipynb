{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "install",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f090b99-6a18-4902-9737-763bc6d4c723"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.33.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install transformers==4.33 -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "imports"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import gc\n",
        "from transformers import NllbTokenizer, AutoModelForSeq2SeqLM, AutoConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "setup"
      },
      "outputs": [],
      "source": [
        "LANGUAGE_TARGET_LABEL = 'nivkh_Cyrl'\n",
        "\n",
        "def fix_tokenizer(tokenizer, new_lang=LANGUAGE_TARGET_LABEL):\n",
        "    old_len = len(tokenizer) - int(new_lang in tokenizer.added_tokens_encoder)\n",
        "    tokenizer.lang_code_to_id[new_lang] = old_len-1\n",
        "    tokenizer.id_to_lang_code[old_len-1] = new_lang\n",
        "    tokenizer.fairseq_tokens_to_ids[\"<mask>\"] = len(tokenizer.sp_model) + len(tokenizer.lang_code_to_id) + tokenizer.fairseq_offset\n",
        "    tokenizer.fairseq_tokens_to_ids.update(tokenizer.lang_code_to_id)\n",
        "    tokenizer.fairseq_ids_to_tokens = {v: k for k, v in tokenizer.fairseq_tokens_to_ids.items()}\n",
        "    if new_lang not in tokenizer._additional_special_tokens:\n",
        "        tokenizer._additional_special_tokens.append(new_lang)\n",
        "    tokenizer.added_tokens_encoder = {}\n",
        "    tokenizer.added_tokens_decoder = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "load_model",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454,
          "referenced_widgets": [
            "ef9ed379877e49e69b633c051dcdb96d",
            "3a3cfb25f09f4bc591c424730cce1905",
            "ca68b669dc3f4e8f85a69e24b9bbf5f0",
            "b646107d342d46f486548a2e971d6b80",
            "de6f9b74278045fab2567651b322d9ef",
            "198e393341db4a0cbfdbf1fc9e9391ca",
            "1193cdc22f0b4fec83751d0744d80f7a",
            "ee0e631887be4ca2820dda372f6e964c",
            "04a16f791e2944a08b49df2377c4d53b",
            "6b2ae4f8c30b45638db83acd1a3bb6c7",
            "3dd4a06a2d404b95a8eae92514391a80",
            "28bbf84f41ba490e964214c9d2367510",
            "7ed464a85fa249a7811ad2b5658ab305",
            "1cbbaaf1e4aa45fd948e5379dd4bcb13",
            "f69678678a54415eb1c7b5fb6cd287a0",
            "097ec56dcd334cea834896fea377846d",
            "4119b81cb9614eac91d970c624112476",
            "e113cea39306441f8337887e273f6a74",
            "282555a633f1406e88df08d10a503d7a",
            "5554ce6c611f44ac9744dc81d97d1055",
            "8bf3de02ddc14585a917eb61a3dd3197",
            "c608d6eb5e9d4eaab2d6219b71c5741c",
            "486985d4510f49b69a279d361b2cc39d",
            "b8172c19432f4547a9aac764d7ea7450",
            "4e1d810f00904f4cb9ee985de37c533c",
            "8bb94218cb044166b39ab884044f3edb",
            "2c6afe47c9154a6dae85505315c1fa6c",
            "447e5ff3dbef4c10bb81f783e9d70402",
            "186d4b9b4f4a469fad1424519ad4ff27",
            "3dc428897bff4068aaac1e0c4fb2cf71",
            "1a8c0753dabf45b187e861109675819a",
            "ee14ac56f4bf44898b9425044def8ff8",
            "dcc78faac96e4d0d82d54959fd718072",
            "bdea73feab7641d1ad8a2abb25ff22b0",
            "dd8e09d2353e49558a5730bccf044ac0",
            "bdaa8482c1e34aa7a46560b790dfa7bb",
            "65f1f24d9f0d42feb773d2e95adc87a6",
            "b1385f631674437491bae62966fbf616",
            "3e586830bc5844658cab9c12032a83dc",
            "50e4b0acb2d94277b08627fcfc4302f4",
            "b4923b5304aa4dce9f5e046c9750e43d",
            "a35aabde0e9c4cd7bf9c7d43f50bbfaa",
            "0b4cfcd165be40b3821343e5624ca39f",
            "0bfde3c5b19f4c309a3cbc416d9c7286",
            "8b982ae0357d43de85939e9a7032b7a2",
            "9be9e5fe8c864bab84fa082228e8d0fd",
            "969a858fa6564d418d1f973ca5e5d332",
            "896536f5917845ee94164efc3950816d",
            "bf0fe31859844350925aeab518b44da7",
            "7192fb2dcd44491d87123b78242bc36d",
            "de14adaeaede432c94e6a14a48d9274a",
            "36160e027841413cae59395c85115a74",
            "2d74012926d34db3ba772f94d4d9d3e6",
            "cb9aca6e8ad44557819fe35e8a718a91",
            "5465b40790de4e6291fa419db6e10a91",
            "6d8eda48190045c29155b63d255fcb0a",
            "829404f95f7a405693c8b3053fde4d6c",
            "434c5d508ce049b4929046bc35ef5193",
            "b306380c89f54557a469780aaa33b1e7",
            "78a46afb782f4409b2e1ee068fabf9dd",
            "c2454c61541f4b2c979cfe8c4db9377b",
            "bbd4688679c34feeb441cda9a9d53c33",
            "27127f02a1c24e9e8707704fdc63172a",
            "1daecdb64ff24d56a860f754d11dd925",
            "7ea9d4184c9d43ba8c8f4fded0be3560",
            "1e88032f55d64c6180ddf7e1c1f237ca"
          ]
        },
        "outputId": "0730f109-4f39-451c-ab1d-92aeb89151bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/918 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ef9ed379877e49e69b633c051dcdb96d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/2.49G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "28bbf84f41ba490e964214c9d2367510"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "486985d4510f49b69a279d361b2cc39d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.01M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bdea73feab7641d1ad8a2abb25ff22b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/3.57k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b982ae0357d43de85939e9a7032b7a2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d8eda48190045c29155b63d255fcb0a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "model_name = \"el-izm/nllb_nivkh_rus_600M_base\"\n",
        "# model_name = \"el-izm/nllb_nivkh_rus_1.3B_base\"\n",
        "# model_name = \"el-izm/nllb_nivkh_rus_600M_extended\"\n",
        "# model_name = \"el-izm/nllb_nivkh_rus_600M_amur_extended\"\n",
        "# model_name = \"el-izm/nllb_nivkh_rus_600M_sakh_extended\"\n",
        "\n",
        "cfg = AutoConfig.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, config=cfg).to('cuda')\n",
        "tokenizer = NllbTokenizer.from_pretrained(model_name)\n",
        "fix_tokenizer(tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "translate_function"
      },
      "outputs": [],
      "source": [
        "def translate(text, src_lang, tgt_lang, max_length='auto', num_beams=4):\n",
        "    lang_map = {\n",
        "        'N': 'nivkh_Cyrl',\n",
        "        'R': 'rus_Cyrl'\n",
        "    }\n",
        "    src_lang_code = lang_map[src_lang]\n",
        "    tgt_lang_code = lang_map[tgt_lang]\n",
        "    tokenizer.src_lang = src_lang_code\n",
        "    encoded = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "    if max_length == 'auto':\n",
        "        max_length = int(32 + 2.0 * encoded.input_ids.shape[1])\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        generated_tokens = model.generate(\n",
        "            **encoded.to(model.device),\n",
        "            forced_bos_token_id=tokenizer.lang_code_to_id[tgt_lang_code],\n",
        "            max_length=max_length,\n",
        "            num_beams=num_beams,\n",
        "            no_repeat_ngram_size=4\n",
        "        )\n",
        "    result = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "interactive",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1896bf6c-239f-495c-bb46-22d9bb9f3b1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Этого человека?\n"
          ]
        }
      ],
      "source": [
        "text = 'Ӿы нивх лу?'\n",
        "src = 'N'\n",
        "trg = 'R'\n",
        "result = translate(text, src, trg)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "cleanup"
      },
      "outputs": [],
      "source": [
        "def cleanup():\n",
        "    # для чистки CUDA при смене модели\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "cleanup()"
      ]
    }
  ]
}